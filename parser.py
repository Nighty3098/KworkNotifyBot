import asyncio
import json
import logging
import random
import re
from typing import Any, Dict, List, Optional

import aiohttp
from aiohttp_socks import ProxyConnector, SocksConnector
from bs4 import BeautifulSoup

from config import config
from proxy_manager import ProxyManager

logger = logging.getLogger(__name__)


class KworkParser:
    def __init__(self, proxy_manager: Optional[ProxyManager] = None):
        self.session = None
        self.proxy_manager = proxy_manager
        self.current_proxy = None

        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3",
            "Accept-Encoding": "gzip, deflate, br",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Cache-Control": "max-age=0",
        }

        self.kwork_headers = {
            **self.headers,
            "Host": "kwork.ru",
            "Referer": "https://kwork.ru/",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "same-origin",
            "Sec-Fetch-User": "?1",
        }

    async def __aenter__(self):
        self.session = await self._create_session()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    async def _create_session(self) -> Optional[aiohttp.ClientSession]:
        try:
            session_kwargs = {
                "headers": self.kwork_headers,
                "timeout": aiohttp.ClientTimeout(total=config.PROXY_TIMEOUT),
            }

            if self.proxy_manager:
                self.current_proxy = self.proxy_manager.get_next_proxy()

                if self.current_proxy:
                    proxy_url = self.current_proxy["url"]
                    host = self.current_proxy.get("host", "unknown")
                    port = self.current_proxy.get("port", "unknown")
                    country = self.current_proxy.get("country", "Unknown")

                    logger.info(
                        f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏: {host}:{port} ({country}) - {self.current_proxy['type']}"
                    )

                    if self.current_proxy["type"] in ["socks4", "socks5"]:
                        try:
                            connector = SocksConnector.from_url(proxy_url)
                            session_kwargs["connector"] = connector
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è SOCKS –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä–∞: {e}")
                            return None
                    elif self.current_proxy["type"] == "http":
                        try:
                            connector = ProxyConnector.from_url(proxy_url)
                            session_kwargs["connector"] = connector
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è HTTP –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä–∞: {e}")
                            return None

                else:
                    logger.warning(
                        "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ"
                    )

            return aiohttp.ClientSession(**session_kwargs)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ—Å—Å–∏–∏: {e}")
            return None

    async def _make_request_with_retry(
        self, url: str, max_retries: int = 3
    ) -> Optional[str]:
        for attempt in range(max_retries):
            try:
                if not self.session:
                    self.session = await self._create_session()
                    if not self.session:
                        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å–µ—Å—Å–∏—é")
                        continue

                logger.info(
                    f"–î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ {url} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})"
                )

                async with self.session.get(url) as response:
                    logger.info(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç: —Å—Ç–∞—Ç—É—Å {response.status}")

                    if response.status == 200:
                        html = await response.text()

                        if self.proxy_manager and self.current_proxy:
                            self.proxy_manager.mark_success(self.current_proxy["url"])

                        return html
                    else:
                        logger.warning(f"–°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞ {response.status} –¥–ª—è {url}")

                        if self.proxy_manager and self.current_proxy:
                            self.proxy_manager.mark_failure(self.current_proxy["url"])

                        if response.status in [403, 429]:
                            logger.info(
                                f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ (—Å—Ç–∞—Ç—É—Å {response.status}), –º–µ–Ω—è–µ–º –ø—Ä–æ–∫—Å–∏..."
                            )
                            await self._rotate_proxy()
                            continue

            except aiohttp.ClientError as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}): {e}"
                )

                if self.proxy_manager and self.current_proxy:
                    self.proxy_manager.mark_failure(self.current_proxy["url"])

                await self._rotate_proxy()

                if attempt < max_retries - 1:
                    await asyncio.sleep(2**attempt)
                continue

            except Exception as e:
                logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
                break

        return None

    async def _rotate_proxy(self):
        """–°–º–µ–Ω–∏—Ç—å –ø—Ä–æ–∫—Å–∏ –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å —Å–µ—Å—Å–∏—é"""
        if self.session:
            await self.session.close()
            self.session = None

        if self.proxy_manager:
            self.current_proxy = self.proxy_manager.get_next_proxy()
            if self.current_proxy:
                host = self.current_proxy.get("host", "unknown")
                port = self.current_proxy.get("port", "unknown")
                country = self.current_proxy.get("country", "Unknown")
                logger.info(f"–°–º–µ–Ω–∏–ª–∏ –ø—Ä–æ–∫—Å–∏ –Ω–∞: {host}:{port} ({country})")
            else:
                logger.info("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ")

        self.session = await self._create_session()

    async def get_projects(self) -> List[Dict[str, Any]]:
        """Fetch projects from Kwork"""
        try:
            logger.info("üîç –ó–∞–ø—Ä–æ—Å –∫ Kwork...")
            url = "https://kwork.ru/projects"

            html = await self._make_request_with_retry(url)

            if not html:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å Kwork –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
                return []

            if len(html) < 100:
                logger.error(f"‚ùå –ü–æ–ª—É—á–µ–Ω —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç: {len(html)} —Å–∏–º–≤–æ–ª–æ–≤")
                return []

            pattern = r"window\.stateData\s*=\s*({.*?});"
            match = re.search(pattern, html, re.DOTALL)

            if match:
                try:
                    state_data = json.loads(match.group(1))

                    if state_data.get("wantsListData", {}).get("wants"):
                        projects = state_data["wantsListData"]["wants"]
                        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–µ–∫—Ç–æ–≤: {len(projects)}")
                        return self._parse_projects(projects)
                except json.JSONDecodeError as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")

            logger.info("–ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
            soup = BeautifulSoup(html, "html.parser")
            script_tags = soup.find_all("script")

            for script in script_tags:
                if script.string and "window.stateData" in script.string:
                    try:
                        lines = script.string.split("\n")
                        for line in lines:
                            if "window.stateData" in line:
                                start = line.find("{")
                                end = line.rfind("}") + 1
                                if start != -1 and end != -1:
                                    json_str = line[start:end]
                                    state_data = json.loads(json_str)

                                    if state_data.get("wantsListData", {}).get("wants"):
                                        projects = state_data["wantsListData"]["wants"]
                                        logger.info(
                                            f"üìä –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–µ–∫—Ç–æ–≤ (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥): {len(projects)}"
                                        )
                                        return self._parse_projects(projects)
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")

            return []

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Kwork: {e}")
            return []
        finally:
            if self.session:
                await self.session.close()
                self.session = None

    def _parse_projects(self, projects_data: List[Dict]) -> List[Dict[str, Any]]:
        parsed_projects = []

        for project in projects_data:
            try:
                project_id = str(project.get("id", ""))
                title = project.get("name", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")

                description = project.get("description", "–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è")
                description = re.sub(r"<[^>]+>", "", description)
                description = description.replace("\r\n", " ")
                words = description.split()
                description = (
                    " ".join(words[:30]) + "..." if len(words) > 30 else description
                )

                price = "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"
                if project.get("priceLimit") and project["priceLimit"] != "0":
                    price = f"{float(project['priceLimit']):.0f} —Ä—É–±."
                elif project.get("possiblePriceLimit"):
                    price = f"{project['possiblePriceLimit']} —Ä—É–±."

                username = project.get("user", {}).get("username", "–ê–Ω–æ–Ω–∏–º")
                time_left = project.get("timeLeft", "")

                project_data = {
                    "id": project_id,
                    "title": title,
                    "description": description,
                    "price": price,
                    "username": username,
                    "time_left": time_left,
                    "url": f"https://kwork.ru/projects/view/{project_id}",
                }

                parsed_projects.append(project_data)

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø—Ä–æ–µ–∫—Ç–∞: {e}")

        return parsed_projects
